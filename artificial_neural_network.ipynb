{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "artificial_neural_network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP6JLo1tGNBg"
      },
      "source": [
        "# Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWZyYmS_UE_L"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxkJoQBkUIHC"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-kVmy3LdCES",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4611208b-b3ed-46c3-c624-577050f8d2b3"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E0Q3aoKUCRX"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKWAkFVGUU0Z"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXUkhkMfU4wq"
      },
      "source": [
        "dataset = pd.read_csv('Churn_Modelling.csv')\n",
        "X = dataset.iloc[:, 3:-1].values # Taking all rows and columns starting from the fourth until the one before last\n",
        "y = dataset.iloc[:, -1].values # Vector that will contain the column of the dependent variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYP9cQTWbzuI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bed1beb4-93d7-46df-bf28-82a593bf95e6"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[619 'France' 'Female' ... 1 1 101348.88]\n",
            " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
            " [502 'France' 'Female' ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 'Female' ... 0 1 42085.58]\n",
            " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
            " [792 'France' 'Female' ... 1 0 38190.78]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38vKGE6Nb2RR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e028166c-58da-4311-e1f4-046a8c4ff204"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 ... 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6bQ0UgSU-NJ"
      },
      "source": [
        "### Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le5MJreAbW52"
      },
      "source": [
        "Label Encoding the \"Gender\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxVKWXxLbczC"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "X[:, 2] = le.fit_transform(X[:, 2]) # Transform the gender column. It will encode them into 0 and 1 classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M1KboxFb6OO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29c8b97b-cfd9-4b99-f5e3-aef97ebe0aab"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[619 'France' 0 ... 1 1 101348.88]\n",
            " [608 'Spain' 0 ... 0 1 112542.58]\n",
            " [502 'France' 0 ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 0 ... 0 1 42085.58]\n",
            " [772 'Germany' 1 ... 1 0 92888.52]\n",
            " [792 'France' 0 ... 1 0 38190.78]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUxGZezpbMcb"
      },
      "source": [
        "One Hot Encoding the \"Geography\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMXC8-KMVirw"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough') # Perform One Hot Encoding for the second column (the geography column)\n",
        "X = np.array(ct.fit_transform(X)) # Remember: the One hot encoded variable will be moved to the beginning of the matrix\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcxwEon-b8nV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20590e7a-98b0-4ee1-e2c0-3fc62582d6fe"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
            " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
            " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
            " ...\n",
            " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
            " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
            " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHol938cW8zd"
      },
      "source": [
        "### Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-TDt0Y_XEfc"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE_FcHyfV3TQ"
      },
      "source": [
        "### Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViCrE00rV8Sk"
      },
      "source": [
        "# Feature Sacling is mandatory for any deep learning, and it should be done for all features regardless of how their values look like\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train) # Sacling applied to all features \n",
        "X_test = sc.transform(X_test) # For the test set apply the scaler (already fitted to the training set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zfEzkRVXIwF"
      },
      "source": [
        "## Part 2 - Building the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvdeScabXtlB"
      },
      "source": [
        "### Initializing the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dtrScHxXQox"
      },
      "source": [
        "# Build an Artificial Neural Network as a sequence of layers (Sequential model from Keras). Since TensorFlow 2.0 keras became a part of TensorFlow\n",
        "ann = tf.keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP6urV6SX7kS"
      },
      "source": [
        "### Adding the input layer and the first hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bppGycBXYCQr"
      },
      "source": [
        "# Add a fully connected layer (first layer in the deep neural network). Dense class creates a fully connected layer\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu')) # units is the number of neurons in the layer. The value 6\n",
        "# is just a magic number that was determined by experimentation (there is no thinking behind, only trial and error). activation is the\n",
        "# the activation function applied at the neurons of the layer. For hidden layers, the rectifier function is used (shortname is 'relu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BELWAc_8YJze"
      },
      "source": [
        "### Adding the second hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JneR0u0sYRTd"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu')) # Exactly the same line as the first layer (with the same number of neurons = 6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyNEe6RXYcU4"
      },
      "source": [
        "### Adding the output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn3x41RBYfvY"
      },
      "source": [
        "# The output layer: Since we have a binary value for the output (dependent variable) 0/1, we need only one neuron at the output layer \n",
        "# For the activation function at the output layer, we used the Sigmoid function as activation function, because not only we get the binary value\n",
        "# But also the probability of having this value (the probability of the customer leaving the bank). Sigmoid is used because the dependent variable is binary.\n",
        "# If the dependent variable is not binary, then the activation function should be 'softmax'\n",
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT4u2S1_Y4WG"
      },
      "source": [
        "## Part 3 - Training the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GWlJChhY_ZI"
      },
      "source": [
        "### Compiling the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG3RrwDXZEaS"
      },
      "source": [
        "# The compile method configures the ann model. the optimizer parameter chooses which optimizer to adjust the neural network\n",
        "# weights. The 'adam' optimizer uses Stochastic Gradient Descent.\n",
        "# Since the dependent variable is binary, the loss function should be 'binary_crossentropy'. If the dependent variable\n",
        "# is not binary, then the loss function should be 'categorical_crossentropy'\n",
        "# metrics parameter contains the list of metrics used to evaluate the neural network \n",
        "\n",
        "ann.compile(optimizer='adam', loss= 'binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QR_G5u7ZLSM"
      },
      "source": [
        "### Training the ANN on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHZ-LKv_ZRb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90bd9069-8f23-4d2f-95aa-a3fa893d0119"
      },
      "source": [
        "# We are training using batch learning, (entering batches of input data to do forward and backpropagation using the Stochastic Gradient Descent)\n",
        "# A batch size of 32 is very commonly used\n",
        "# epochs: the number of times the full dataset is entered into the neural network. Choose any number, but make sure it's large\n",
        "# enough so that the network can properly learn and find correlations. 100 is just a magic number\n",
        "ann.fit(X_train, y_train, batch_size=32, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 1s 1ms/step - loss: 0.8623 - accuracy: 0.3795\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.5545 - accuracy: 0.7926\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.7978\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4722 - accuracy: 0.7907\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7978\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.7977\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4288 - accuracy: 0.8027\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.8066\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3965 - accuracy: 0.8226\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3993 - accuracy: 0.8117\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3860 - accuracy: 0.8197\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3841 - accuracy: 0.8234\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3695 - accuracy: 0.8295\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3776 - accuracy: 0.8401\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3556 - accuracy: 0.8550\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3566 - accuracy: 0.8496\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3474 - accuracy: 0.8538\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3392 - accuracy: 0.8610\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3451 - accuracy: 0.8592\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3626 - accuracy: 0.8453\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3447 - accuracy: 0.8646\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3486 - accuracy: 0.8569\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3477 - accuracy: 0.8596\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3493 - accuracy: 0.8541\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3482 - accuracy: 0.8527\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3453 - accuracy: 0.8573\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3418 - accuracy: 0.8584\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3430 - accuracy: 0.8571\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3391 - accuracy: 0.8585\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3415 - accuracy: 0.8626\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3477 - accuracy: 0.8569\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3411 - accuracy: 0.8580\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3455 - accuracy: 0.8555\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3419 - accuracy: 0.8574\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.8680\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3384 - accuracy: 0.8637\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8702\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3401 - accuracy: 0.8615\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3331 - accuracy: 0.8646\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3433 - accuracy: 0.8575\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3410 - accuracy: 0.8628\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3418 - accuracy: 0.8615\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8661\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.8625\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8667\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3393 - accuracy: 0.8562\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3237 - accuracy: 0.8702\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8612\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3399 - accuracy: 0.8615\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8630\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3444 - accuracy: 0.8541\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3355 - accuracy: 0.8621\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8663\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8628\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8645\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3398 - accuracy: 0.8576\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3392 - accuracy: 0.8615\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3240 - accuracy: 0.8677\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8606\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8642\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8650\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8632\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8645\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8610\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8583\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8619\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3196 - accuracy: 0.8686\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3251 - accuracy: 0.8631\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3223 - accuracy: 0.8665\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8633\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8602\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3132 - accuracy: 0.8673\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8622\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8608\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8640\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8662\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3392 - accuracy: 0.8567\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3372 - accuracy: 0.8611\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3186 - accuracy: 0.8692\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3390 - accuracy: 0.8556\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8630\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3190 - accuracy: 0.8731\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3208 - accuracy: 0.8694\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8639\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3380 - accuracy: 0.8626\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3198 - accuracy: 0.8680\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8634\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8652\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8589\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8635\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8600\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8667\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8657\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3211 - accuracy: 0.8670\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3215 - accuracy: 0.8667\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3225 - accuracy: 0.8671\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8681\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8637\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3236 - accuracy: 0.8675\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.8655\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8b1f9c3750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJj5k2MxZga3"
      },
      "source": [
        "## Part 4 - Making the predictions and evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84QFoqGYeXHL"
      },
      "source": [
        "### Predicting the result of a single observation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGRo3eacgDdC"
      },
      "source": [
        "**Homework**\n",
        "\n",
        "Use our ANN model to predict if the customer with the following informations will leave the bank: \n",
        "\n",
        "Geography: France\n",
        "\n",
        "Credit Score: 600\n",
        "\n",
        "Gender: Male\n",
        "\n",
        "Age: 40 years old\n",
        "\n",
        "Tenure: 3 years\n",
        "\n",
        "Balance: \\$ 60000\n",
        "\n",
        "Number of Products: 2\n",
        "\n",
        "Does this customer have a credit card? Yes\n",
        "\n",
        "Is this customer an Active Member: Yes\n",
        "\n",
        "Estimated Salary: \\$ 50000\n",
        "\n",
        "So, should we say goodbye to that customer?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhU1LTgPg-kH"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d8IoCCkeWGL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5b2f18d-f74f-49b6-e440-a3500d6f7c14"
      },
      "source": [
        "# Remember: The encoding of 'France' using One Hot Encoding was: 1 0 0. This should be entered instead of the string 'France'\n",
        "# and male is encoded (using Label Encoder) is 1\n",
        "# Remember: the same scaling that was applied to the training and testing sets should be applied to the input. Hence the use of the sc object.\n",
        "# Make sure you are only calling transform (and not fit_transform because fitting should only be applied to the training set)\n",
        "# predict method returns a probability, we defined a threshold of staying/leaving the bank of 0.5\n",
        "print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) > 0.5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[False]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGjx94g2n7OV"
      },
      "source": [
        "Therefore, our ANN model predicts that this customer stays in the bank!\n",
        "\n",
        "**Important note 1:** Notice that the values of the features were all input in a double pair of square brackets. That's because the \"predict\" method always expects a 2D array as the format of its inputs. And putting our values into a double pair of square brackets makes the input exactly a 2D array.\n",
        "\n",
        "**Important note 2:** Notice also that the \"France\" country was not input as a string in the last column but as \"1, 0, 0\" in the first three columns. That's because of course the predict method expects the one-hot-encoded values of the state, and as we see in the first row of the matrix of features X, \"France\" was encoded as \"1, 0, 0\". And be careful to include these values in the first three columns, because the dummy variables are always created in the first columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7yx47jPZt11"
      },
      "source": [
        "### Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIyEeQdRZwgs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16d0198d-23ce-4b9c-938d-37c7f86544e3"
      },
      "source": [
        "y_pred = ann.predict(X_test)\n",
        "y_pred = (y_pred > 0.5) # converted the predicted probabilities into 1 (if > 0.5 threshold) or 0 otherwise\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.reshape(len(y_test), 1)), 1)) # Show the prediction of the test set side by side with the actual values of the test set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " ...\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0oyfLWoaEGw"
      },
      "source": [
        "### Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci6K_r6LaF6P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4d854e9e-22d5-432f-f6e5-a102fe3ae0bd"
      },
      "source": [
        "# Show the confusion matrix and the the accuracy score for the predictions of the test set.\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1516   79]\n",
            " [ 200  205]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8605"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}